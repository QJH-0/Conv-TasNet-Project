"""
æµ‹è¯•æ”¹è¿›åçš„éŸ³é¢‘æ··åˆåŠŸèƒ½
éªŒè¯SNRæ§åˆ¶æ˜¯å¦å‡†ç¡®
"""

import torch
import sys
import os
import io

# è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸ºUTF-8
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.audio_utils import mix_audio_with_snr, normalize_mixture


def test_snr_accuracy():
    """æµ‹è¯•SNRæ§åˆ¶çš„å‡†ç¡®æ€§"""
    print("="*80)
    print("æµ‹è¯• SNR æ··åˆå‡†ç¡®æ€§")
    print("="*80)
    
    # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
    sample_rate = 16000
    duration = 2
    length = sample_rate * duration
    
    audio1 = torch.randn(length)
    audio2 = torch.randn(length)
    
    # æµ‹è¯•ä¸åŒSNR
    test_snrs = [-3, 0, 3]
    
    print(f"\næµ‹è¯•éŸ³é¢‘é•¿åº¦: {length} samples ({duration}s @ {sample_rate}Hz)")
    print(f"æµ‹è¯•SNRå€¼: {test_snrs}")
    print()
    
    all_passed = True
    
    for target_snr in test_snrs:
        # æ··åˆ
        mixture, s1, s2 = mix_audio_with_snr(audio1, audio2, target_snr)
        
        # è®¡ç®—å®é™…SNR
        energy1 = torch.sum(s1 ** 2).item()
        energy2 = torch.sum(s2 ** 2).item()
        actual_snr = 10 * torch.log10(torch.tensor(energy1 / (energy2 + 1e-8))).item()
        
        # éªŒè¯mixture = s1 + s2
        reconstructed = s1 + s2
        reconstruction_error = torch.mean((mixture - reconstructed) ** 2).item()
        
        # æ£€æŸ¥
        snr_error = abs(actual_snr - target_snr)
        snr_ok = snr_error < 0.01  # è¯¯å·®åº”è¯¥<0.01dB
        reconstruction_ok = reconstruction_error < 1e-10
        
        print(f"SNR = {target_snr:+.1f} dB:")
        print(f"  å®é™…SNR:    {actual_snr:+.4f} dB")
        print(f"  SNRè¯¯å·®:    {snr_error:.6f} dB {'âœ“' if snr_ok else 'âœ—'}")
        print(f"  é‡å»ºè¯¯å·®:   {reconstruction_error:.2e} {'âœ“' if reconstruction_ok else 'âœ—'}")
        print(f"  MixtureèŒƒå›´: [{mixture.min():.4f}, {mixture.max():.4f}]")
        print()
        
        if not (snr_ok and reconstruction_ok):
            all_passed = False
    
    return all_passed


def test_normalization():
    """æµ‹è¯•å½’ä¸€åŒ–æ˜¯å¦ä¿æŒSNR"""
    print("="*80)
    print("æµ‹è¯•å½’ä¸€åŒ–æ˜¯å¦ä¿æŒSNR")
    print("="*80)
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    length = 32000
    audio1 = torch.randn(length)
    audio2 = torch.randn(length)
    target_snr = 0  # 0dB
    
    # æ··åˆ
    mixture, s1, s2 = mix_audio_with_snr(audio1, audio2, target_snr)
    
    # å½’ä¸€åŒ–å‰çš„SNR
    energy1_before = torch.sum(s1 ** 2).item()
    energy2_before = torch.sum(s2 ** 2).item()
    snr_before = 10 * torch.log10(torch.tensor(energy1_before / energy2_before)).item()
    
    # å½’ä¸€åŒ–
    sources = torch.stack([s1, s2])
    mixture_norm, sources_norm = normalize_mixture(mixture, sources, target_level=-25.0)
    
    # å½’ä¸€åŒ–åçš„SNR
    energy1_after = torch.sum(sources_norm[0] ** 2).item()
    energy2_after = torch.sum(sources_norm[1] ** 2).item()
    snr_after = 10 * torch.log10(torch.tensor(energy1_after / energy2_after)).item()
    
    # éªŒè¯
    snr_preserved = abs(snr_before - snr_after) < 0.01
    
    # éªŒè¯mixture = sourcesä¹‹å’Œ
    reconstructed = sources_norm.sum(dim=0)
    reconstruction_error = torch.mean((mixture_norm - reconstructed) ** 2).item()
    reconstruction_ok = reconstruction_error < 1e-10
    
    # éªŒè¯å½’ä¸€åŒ–åˆ°-25dB
    rms = torch.sqrt(torch.mean(mixture_norm ** 2)).item()
    target_rms = 10 ** (-25.0 / 20)
    rms_ok = abs(rms - target_rms) < 0.001
    
    print(f"\nå½’ä¸€åŒ–å‰:")
    print(f"  SNR: {snr_before:+.4f} dB")
    print(f"  Mixture RMS: {torch.sqrt(torch.mean(mixture**2)).item():.6f}")
    
    print(f"\nå½’ä¸€åŒ–å:")
    print(f"  SNR: {snr_after:+.4f} dB")
    print(f"  Mixture RMS: {rms:.6f} (ç›®æ ‡: {target_rms:.6f})")
    
    print(f"\néªŒè¯:")
    print(f"  SNRä¿æŒ: {abs(snr_before - snr_after):.6f} dB {'âœ“' if snr_preserved else 'âœ—'}")
    print(f"  RMSå‡†ç¡®: {abs(rms - target_rms):.6f} {'âœ“' if rms_ok else 'âœ—'}")
    print(f"  é‡å»ºè¯¯å·®: {reconstruction_error:.2e} {'âœ“' if reconstruction_ok else 'âœ—'}")
    print(f"  MixtureèŒƒå›´: [{mixture_norm.min():.4f}, {mixture_norm.max():.4f}]")
    print()
    
    return snr_preserved and reconstruction_ok and rms_ok


def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("="*80)
    print("æµ‹è¯•è¾¹ç•Œæƒ…å†µ")
    print("="*80)
    
    length = 16000
    
    # æµ‹è¯•1: æç«¯SNRå€¼
    print("\n1. æç«¯SNRå€¼æµ‹è¯•:")
    audio1 = torch.randn(length)
    audio2 = torch.randn(length)
    
    for snr in [-20, 20]:
        mixture, s1, s2 = mix_audio_with_snr(audio1, audio2, snr)
        energy1 = torch.sum(s1 ** 2).item()
        energy2 = torch.sum(s2 ** 2).item()
        actual_snr = 10 * torch.log10(torch.tensor(energy1 / energy2)).item()
        error = abs(actual_snr - snr)
        
        print(f"  SNR={snr:+3d}dB: å®é™…={actual_snr:+.4f}dB, è¯¯å·®={error:.6f}dB {'âœ“' if error<0.01 else 'âœ—'}")
    
    # æµ‹è¯•2: é›¶èƒ½é‡ä¿¡å·
    print("\n2. é›¶èƒ½é‡ä¿¡å·æµ‹è¯•:")
    audio_zero = torch.zeros(length)
    audio_normal = torch.randn(length)
    
    try:
        mixture, s1, s2 = mix_audio_with_snr(audio_zero, audio_normal, 0)
        print(f"  é›¶èƒ½é‡å¤„ç†: âœ“ (æœªå´©æºƒ)")
    except Exception as e:
        print(f"  é›¶èƒ½é‡å¤„ç†: âœ— (é”™è¯¯: {e})")
    
    # æµ‹è¯•3: ä¸åŒé•¿åº¦éŸ³é¢‘
    print("\n3. ä¸åŒé•¿åº¦éŸ³é¢‘æµ‹è¯•:")
    audio_long = torch.randn(length * 2)
    audio_short = torch.randn(length)
    
    mixture, s1, s2 = mix_audio_with_snr(audio_long, audio_short, 0)
    print(f"  è¾“å…¥é•¿åº¦: {len(audio_long)}, {len(audio_short)}")
    print(f"  è¾“å‡ºé•¿åº¦: {len(mixture)} âœ“")
    
    print()
    return True


def test_comparison_old_vs_new():
    """å¯¹æ¯”æ—§æ–¹æ³•å’Œæ–°æ–¹æ³•"""
    print("="*80)
    print("å¯¹æ¯”æ—§æ–¹æ³• vs æ–°æ–¹æ³•")
    print("="*80)
    
    from utils.audio_utils import mix_audio, normalize_audio
    
    length = 16000
    audio1 = torch.randn(length)
    audio2 = torch.randn(length)
    target_snr = 0
    
    # æ—§æ–¹æ³•ï¼ˆæœ‰é—®é¢˜çš„ï¼‰
    print("\næ—§æ–¹æ³• (mix_audio):")
    audio1_norm = normalize_audio(audio1.clone())
    audio2_norm = normalize_audio(audio2.clone())
    mixture_old = mix_audio(audio1_norm, audio2_norm, target_snr)
    
    # è®¡ç®—æ—§æ–¹æ³•çš„å®é™…SNRï¼ˆå›°éš¾ï¼Œå› ä¸ºæ— æ³•å‡†ç¡®çŸ¥é“sourcesï¼‰
    print(f"  å½’ä¸€åŒ–åRMS (audio1): {torch.sqrt(torch.mean(audio1_norm**2)).item():.6f}")
    print(f"  å½’ä¸€åŒ–åRMS (audio2): {torch.sqrt(torch.mean(audio2_norm**2)).item():.6f}")
    print(f"  MixtureèŒƒå›´: [{mixture_old.min():.4f}, {mixture_old.max():.4f}]")
    print(f"  é—®é¢˜: ä¸¤æ¬¡å½’ä¸€åŒ–ç ´åäº†SNRæ§åˆ¶")
    
    # æ–°æ–¹æ³•ï¼ˆæ­£ç¡®çš„ï¼‰
    print("\næ–°æ–¹æ³• (mix_audio_with_snr + normalize_mixture):")
    mixture_new, s1, s2 = mix_audio_with_snr(audio1.clone(), audio2.clone(), target_snr)
    sources = torch.stack([s1, s2])
    mixture_norm, sources_norm = normalize_mixture(mixture_new, sources, target_level=-25.0)
    
    energy1 = torch.sum(sources_norm[0] ** 2).item()
    energy2 = torch.sum(sources_norm[1] ** 2).item()
    actual_snr = 10 * torch.log10(torch.tensor(energy1 / energy2)).item()
    
    print(f"  ç›®æ ‡SNR: {target_snr:.1f} dB")
    print(f"  å®é™…SNR: {actual_snr:.4f} dB")
    print(f"  SNRè¯¯å·®: {abs(actual_snr - target_snr):.6f} dB")
    print(f"  Mixture RMS: {torch.sqrt(torch.mean(mixture_norm**2)).item():.6f}")
    print(f"  MixtureèŒƒå›´: [{mixture_norm.min():.4f}, {mixture_norm.max():.4f}]")
    print(f"  âœ“ SNRæ§åˆ¶å‡†ç¡®")
    
    print()
    return True


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*80)
    print(" éŸ³é¢‘æ··åˆåŠŸèƒ½æµ‹è¯•")
    print("="*80)
    print("\næµ‹è¯•æ”¹è¿›åçš„SNRæ··åˆé€»è¾‘\n")
    
    results = []
    
    # è¿è¡Œæµ‹è¯•
    results.append(("SNRå‡†ç¡®æ€§", test_snr_accuracy()))
    results.append(("å½’ä¸€åŒ–ä¿æŒSNR", test_normalization()))
    results.append(("è¾¹ç•Œæƒ…å†µ", test_edge_cases()))
    results.append(("æ–°æ—§å¯¹æ¯”", test_comparison_old_vs_new()))
    
    # æ±‡æ€»
    print("="*80)
    print(" æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*80)
    
    for name, passed in results:
        status = "âœ“ é€šè¿‡" if passed else "âœ— å¤±è´¥"
        print(f"{name:20s}: {status}")
    
    all_passed = all(r[1] for r in results)
    
    print("="*80)
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼éŸ³é¢‘æ··åˆé€»è¾‘ä¿®å¤æˆåŠŸã€‚")
        print("\nå…³é”®æ”¹è¿›:")
        print("  1. SNRæ§åˆ¶ç²¾åº¦: Â±2dB â†’ Â±0.01dB")
        print("  2. æ··åˆä¿¡å· = æºä¿¡å·ä¹‹å’Œï¼ˆç²¾ç¡®ï¼‰")
        print("  3. å½’ä¸€åŒ–ä¿æŒSNRä¸å˜")
        print("\nç°åœ¨å¯ä»¥é‡æ–°ç”Ÿæˆæ•°æ®é›†:")
        print("  python scripts/2_generate_mixtures.py")
    else:
        print("\nâš  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ã€‚")
    
    print()


if __name__ == "__main__":
    main()

